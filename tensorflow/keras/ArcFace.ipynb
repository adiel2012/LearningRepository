{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598369558915",
   "display_name": "Python 3.8.4 64-bit ('environment': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcFace: Additive Angular Margin Loss for Deep Face Recognition.  \n",
    "[click here](https://arxiv.org/abs/1801.07698)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, X, labels, batch_size) :\n",
    "    self.X = X\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    self.shuffle = True\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def __iter__(self):\n",
    "    \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "    for item in (self[i] for i in range(len(self))):\n",
    "      yield item  \n",
    "    \n",
    "  def __len__(self) :\n",
    "    #self.on_epoch_end()\n",
    "    result = (np.ceil(len(self.X) / float(self.batch_size))).astype(np.int)\n",
    "    return result\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indexes = np.arange(len(self.labels))\n",
    "    if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)\n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "    batch_x = [self.X[k] for k in indexes]\n",
    "    batch_y = [self.labels[k] for k in indexes] \n",
    "    X = np.array(batch_x, dtype=np.int32)\n",
    "    Y = np.array(batch_y)\n",
    "    X = np.concatenate((X, Y), axis=1)\n",
    "    print(X.shape)\n",
    "     \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginPenaltyLogists(layers.Layer):\n",
    "    \"\"\"ArcMarginPenaltyLogists\"\"\"\n",
    "    def __init__(self, num_classes, margin=0.5, logist_scale=64, **kwargs):\n",
    "        super(ArcMarginPenaltyLogists, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.margin = margin\n",
    "        self.logist_scale = logist_scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_variable(\n",
    "            \"weights\", shape=[int(input_shape[-1]), self.num_classes])\n",
    "        self.cos_m = tf.identity(math.cos(self.margin), name='cos_m')\n",
    "        self.sin_m = tf.identity(math.sin(self.margin), name='sin_m')\n",
    "        self.th = tf.identity(math.cos(math.pi - self.margin), name='th')\n",
    "        self.mm = tf.multiply(self.sin_m, self.margin, name='mm')\n",
    "\n",
    "    def call(self, embds, labels):\n",
    "        normed_embds = tf.nn.l2_normalize(embds, axis=1, name='normed_embd')\n",
    "        normed_w = tf.nn.l2_normalize(self.w, axis=0, name='normed_weights')\n",
    "\n",
    "        cos_t = tf.matmul(normed_embds, normed_w, name='cos_t')\n",
    "        sin_t = tf.sqrt(1. - cos_t ** 2, name='sin_t')\n",
    "\n",
    "        cos_mt = tf.subtract(\n",
    "            cos_t * self.cos_m, sin_t * self.sin_m, name='cos_mt')\n",
    "\n",
    "        cos_mt = tf.where(cos_t > self.th, cos_mt, cos_t - self.mm)\n",
    "\n",
    "        mask = tf.one_hot(tf.cast(labels, tf.int32), depth=self.num_classes,\n",
    "                          name='one_hot_mask')\n",
    "\n",
    "        logists = tf.where(mask == 1., cos_mt, cos_t)\n",
    "        logists = tf.multiply(logists, self.logist_scale, 'arcface_logist')\n",
    "\n",
    "        return logists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_patterns = 2000\n",
    "num_features = 2\n",
    "mu, sigma = 0, 0.5\n",
    "num_classes = 2\n",
    "num_hidden_neurons = 4\n",
    "Xred = np.random.normal(mu, sigma, (num_patterns, num_features)) + np.array([1,1])\n",
    "Yred = np.zeros(num_patterns, dtype=int)\n",
    "Xblue = np.random.normal(mu, sigma, (num_patterns, num_features)) + np.array([-1,-1])\n",
    "Yblue = np.ones(num_patterns, dtype=int)\n",
    "X = np.concatenate((Xred, Xblue), axis=0)\n",
    "Y = np.concatenate((Yred, Yblue), axis=0)\n",
    "Y = np.reshape(Y, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(num_features+num_classes))\n",
    "output_1 = layers.Dense(64, activation='relu')(inputs[:,0:num_features])\n",
    "output_2 = layers.Dense(64, activation='relu')(output_1)\n",
    "predictions = ArcMarginPenaltyLogists(num_classes)(output_2, inputs[:,num_features: num_features+num_classes])  \n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ccuracy: 0.0000e+00\nEpoch 30/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.4657 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.7346 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 9.7656 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 9.6173 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 9.6116 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6270 - accuracy: 0.0000e+00 - val_loss: 9.4201 - val_accuracy: 0.0000e+00\nEpoch 31/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.2036 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.8261 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 9.7165 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 9.6713 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 9.6364 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6189 - accuracy: 0.0000e+00 - val_loss: 9.4075 - val_accuracy: 0.0000e+00\nEpoch 32/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.5520 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.9170 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n15/36 [===========>..................] - ETA: 0s - loss: 9.6175 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n20/36 [===============>..............] - ETA: 0s - loss: 9.6146 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n26/36 [====================>.........] - ETA: 0s - loss: 9.5941 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 9.5978 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 12ms/step - loss: 9.6300 - accuracy: 0.0000e+00 - val_loss: 9.3999 - val_accuracy: 0.0000e+00\nEpoch 33/50\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.4679 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.4344 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n16/36 [============>.................] - ETA: 0s - loss: 9.5532 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n23/36 [==================>...........] - ETA: 0s - loss: 9.5703 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n31/36 [========================>.....] - ETA: 0s - loss: 9.5433 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6235 - accuracy: 0.0000e+00 - val_loss: 9.4129 - val_accuracy: 0.0000e+00\nEpoch 34/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.4060 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.6807 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n17/36 [=============>................] - ETA: 0s - loss: 9.6217 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n25/36 [===================>..........] - ETA: 0s - loss: 9.6852 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n33/36 [==========================>...] - ETA: 0s - loss: 9.6859 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6288 - accuracy: 0.0000e+00 - val_loss: 9.4125 - val_accuracy: 0.0000e+00\nEpoch 35/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.4280 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.9005 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n17/36 [=============>................] - ETA: 0s - loss: 9.7676 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n23/36 [==================>...........] - ETA: 0s - loss: 9.7066 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n30/36 [========================>.....] - ETA: 0s - loss: 9.6079 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 9.6308 - accuracy: 0.0000e+00 - val_loss: 9.3799 - val_accuracy: 0.0000e+00\nEpoch 36/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.5816 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 8/36 [=====>........................] - ETA: 0s - loss: 9.5989 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n15/36 [===========>..................] - ETA: 0s - loss: 9.6315 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n22/36 [=================>............] - ETA: 0s - loss: 9.5301 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n28/36 [======================>.......] - ETA: 0s - loss: 9.5857 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - ETA: 0s - loss: 9.6282 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 9.6282 - accuracy: 0.0000e+00 - val_loss: 9.3984 - val_accuracy: 0.0000e+00\nEpoch 37/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.9171 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 8/36 [=====>........................] - ETA: 0s - loss: 9.7956 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n15/36 [===========>..................] - ETA: 0s - loss: 9.6747 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n22/36 [=================>............] - ETA: 0s - loss: 9.5808 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n30/36 [========================>.....] - ETA: 0s - loss: 9.6148 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 9.6282 - accuracy: 0.0000e+00 - val_loss: 9.4079 - val_accuracy: 0.0000e+00\nEpoch 38/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.1271 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 8/36 [=====>........................] - ETA: 0s - loss: 10.0205 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n15/36 [===========>..................] - ETA: 0s - loss: 9.6937 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n23/36 [==================>...........] - ETA: 0s - loss: 9.7342 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n30/36 [========================>.....] - ETA: 0s - loss: 9.7360 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6243 - accuracy: 0.0000e+00 - val_loss: 9.4197 - val_accuracy: 0.0000e+00\nEpoch 39/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.6984 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.6884 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n16/36 [============>.................] - ETA: 0s - loss: 9.5405 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 9.6293 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 9.6224 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6258 - accuracy: 0.0000e+00 - val_loss: 9.3986 - val_accuracy: 0.0000e+00\nEpoch 40/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 8.7600 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.6374 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 9.7335 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 9.7324 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 9.6775 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6297 - accuracy: 0.0000e+00 - val_loss: 9.4104 - val_accuracy: 0.0000e+00\nEpoch 41/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.3479 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 10.0236 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 9.6088 - accuracy: 0.0000e+00 \n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 9.5409 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 9.6342 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6267 - accuracy: 0.0000e+00 - val_loss: 9.4159 - val_accuracy: 0.0000e+00\nEpoch 42/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.6791 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.7249 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n16/36 [============>.................] - ETA: 0s - loss: 9.6013 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n23/36 [==================>...........] - ETA: 0s - loss: 9.6057 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n30/36 [========================>.....] - ETA: 0s - loss: 9.5969 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6273 - accuracy: 0.0000e+00 - val_loss: 9.4178 - val_accuracy: 0.0000e+00\nEpoch 43/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.3803 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.5403 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n16/36 [============>.................] - ETA: 0s - loss: 9.7892 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n23/36 [==================>...........] - ETA: 0s - loss: 9.6492 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n30/36 [========================>.....] - ETA: 0s - loss: 9.6204 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n35/36 [============================>.] - ETA: 0s - loss: 9.6376 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 9.6232 - accuracy: 0.0000e+00 - val_loss: 9.4072 - val_accuracy: 0.0000e+00\nEpoch 44/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.7942 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.7988 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n17/36 [=============>................] - ETA: 0s - loss: 9.7007 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n25/36 [===================>..........] - ETA: 0s - loss: 9.7072 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n32/36 [=========================>....] - ETA: 0s - loss: 9.6438 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 9.6285 - accuracy: 0.0000e+00 - val_loss: 9.4138 - val_accuracy: 0.0000e+00\nEpoch 45/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.3403 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.5939 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 9.4782 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n25/36 [===================>..........] - ETA: 0s - loss: 9.5363 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n32/36 [=========================>....] - ETA: 0s - loss: 9.5930 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 9.6281 - accuracy: 0.0000e+00 - val_loss: 9.4197 - val_accuracy: 0.0000e+00\nEpoch 46/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.1955 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.8934 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 9.6557 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 9.5222 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 9.5619 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 9.6244 - accuracy: 0.0000e+00 - val_loss: 9.4085 - val_accuracy: 0.0000e+00\nEpoch 47/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.3489 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 8/36 [=====>........................] - ETA: 0s - loss: 9.5225 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n16/36 [============>.................] - ETA: 0s - loss: 9.6703 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n24/36 [===================>..........] - ETA: 0s - loss: 9.6514 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n31/36 [========================>.....] - ETA: 0s - loss: 9.6565 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 9.6264 - accuracy: 0.0000e+00 - val_loss: 9.4016 - val_accuracy: 0.0000e+00\nEpoch 48/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 8.7483 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 8/36 [=====>........................] - ETA: 0s - loss: 9.6812 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 9.4898 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n25/36 [===================>..........] - ETA: 0s - loss: 9.6021 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n33/36 [==========================>...] - ETA: 0s - loss: 9.5909 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 9.6278 - accuracy: 0.0000e+00 - val_loss: 9.4142 - val_accuracy: 0.0000e+00\nEpoch 49/50\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 9.2273 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 9.8625 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n18/36 [==============>...............] - ETA: 0s - loss: 9.9653 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n26/36 [====================>.........] - ETA: 0s - loss: 9.8177 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n34/36 [===========================>..] - ETA: 0s - loss: 9.6089 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 9.6230 - accuracy: 0.0000e+00 - val_loss: 9.4163 - val_accuracy: 0.0000e+00\nEpoch 50/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 10.1955 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3\n 7/36 [====>.........................] - ETA: 0s - loss: 9.5817 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n15/36 [===========>..................] - ETA: 0s - loss: 9.5118 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n22/36 [=================>............] - ETA: 0s - loss: 9.5356 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n29/36 [=======================>......] - ETA: 0s - loss: 9.5519 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - ETA: 0s - loss: 9.6286 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 9.6286 - accuracy: 0.0000e+00 - val_loss: 9.4056 - val_accuracy: 0.0000e+00\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2583bd12af0>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=34)\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "my_training_batch_generator = My_Custom_Generator(X_train, y_train, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(X_test, y_test, batch_size)\n",
    "\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  my_training_batch_generator,\n",
    "  epochs=num_epochs,\n",
    "  validation_data = my_validation_batch_generator,\n",
    "  validation_steps=len(my_validation_batch_generator)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}