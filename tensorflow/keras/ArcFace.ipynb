{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598369558915",
   "display_name": "Python 3.8.4 64-bit ('environment': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comming soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, X, labels, batch_size) :\n",
    "    self.X = X\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    self.shuffle = True\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def __iter__(self):\n",
    "    \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "    for item in (self[i] for i in range(len(self))):\n",
    "      yield item  \n",
    "    \n",
    "  def __len__(self) :\n",
    "    #self.on_epoch_end()\n",
    "    result = (np.ceil(len(self.X) / float(self.batch_size))).astype(np.int)\n",
    "    return result\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indexes = np.arange(len(self.labels))\n",
    "    if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)\n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "    batch_x = [self.X[k] for k in indexes]\n",
    "    batch_y = [self.labels[k] for k in indexes] \n",
    "    X = np.array(batch_x, dtype=np.int32)\n",
    "    Y = np.array(batch_y)\n",
    "    X = np.concatenate((X, Y), axis=1)\n",
    "    print(X.shape)\n",
    "     \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginPenaltyLogists(layers.Layer):\n",
    "    \"\"\"ArcMarginPenaltyLogists\"\"\"\n",
    "    def __init__(self, num_classes, margin=0.5, logist_scale=64, **kwargs):\n",
    "        super(ArcMarginPenaltyLogists, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.margin = margin\n",
    "        self.logist_scale = logist_scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_variable(\n",
    "            \"weights\", shape=[int(input_shape[-1]), self.num_classes])\n",
    "        self.cos_m = tf.identity(math.cos(self.margin), name='cos_m')\n",
    "        self.sin_m = tf.identity(math.sin(self.margin), name='sin_m')\n",
    "        self.th = tf.identity(math.cos(math.pi - self.margin), name='th')\n",
    "        self.mm = tf.multiply(self.sin_m, self.margin, name='mm')\n",
    "\n",
    "    def call(self, embds, labels):\n",
    "        normed_embds = tf.nn.l2_normalize(embds, axis=1, name='normed_embd')\n",
    "        normed_w = tf.nn.l2_normalize(self.w, axis=0, name='normed_weights')\n",
    "\n",
    "        cos_t = tf.matmul(normed_embds, normed_w, name='cos_t')\n",
    "        sin_t = tf.sqrt(1. - cos_t ** 2, name='sin_t')\n",
    "\n",
    "        cos_mt = tf.subtract(\n",
    "            cos_t * self.cos_m, sin_t * self.sin_m, name='cos_mt')\n",
    "\n",
    "        cos_mt = tf.where(cos_t > self.th, cos_mt, cos_t - self.mm)\n",
    "\n",
    "        mask = tf.one_hot(tf.cast(labels, tf.int32), depth=self.num_classes,\n",
    "                          name='one_hot_mask')\n",
    "\n",
    "        logists = tf.where(mask == 1., cos_mt, cos_t)\n",
    "        logists = tf.multiply(logists, self.logist_scale, 'arcface_logist')\n",
    "\n",
    "        return logists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_patterns = 2000\n",
    "num_features = 2\n",
    "mu, sigma = 0, 0.5\n",
    "num_classes = 2\n",
    "num_hidden_neurons = 4\n",
    "Xred = np.random.normal(mu, sigma, (num_patterns, num_features)) + np.array([1,1])\n",
    "Yred = np.zeros(num_patterns, dtype=int)\n",
    "Xblue = np.random.normal(mu, sigma, (num_patterns, num_features)) + np.array([-1,-1])\n",
    "Yblue = np.ones(num_patterns, dtype=int)\n",
    "X = np.concatenate((Xred, Xblue), axis=0)\n",
    "Y = np.concatenate((Yred, Yblue), axis=0)\n",
    "Y = np.reshape(Y, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(num_features+num_classes))\n",
    "output_1 = layers.Dense(64, activation='relu')(inputs[:,0:num_features])\n",
    "output_2 = layers.Dense(64, activation='relu')(output_1)\n",
    "predictions = ArcMarginPenaltyLogists(num_classes)(output_2, inputs[:,num_features: num_features+num_classes])  \n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "00, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 7.1843 - accuracy: 0.0000e+00 - val_loss: 7.0436 - val_accuracy: 0.0000e+00\nEpoch 5/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 6.2105 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.1285 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 7.1696 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n26/36 [====================>.........] - ETA: 0s - loss: 7.1687 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n34/36 [===========================>..] - ETA: 0s - loss: 7.1756 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 7.1756 - accuracy: 0.0000e+00 - val_loss: 7.0184 - val_accuracy: 0.0000e+00\nEpoch 6/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.1949 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 8/36 [=====>........................] - ETA: 0s - loss: 7.2301 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n16/36 [============>.................] - ETA: 0s - loss: 7.1084 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 7.1897 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n32/36 [=========================>....] - ETA: 0s - loss: 7.1548 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 7.1806 - accuracy: 0.0000e+00 - val_loss: 7.0296 - val_accuracy: 0.0000e+00\nEpoch 7/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.1635 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.2537 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 7.2437 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n24/36 [===================>..........] - ETA: 0s - loss: 7.1786 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 7.2062 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 7.1913 - accuracy: 0.0000e+00 - val_loss: 7.0202 - val_accuracy: 0.0000e+00\nEpoch 8/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 8.0170 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 8/36 [=====>........................] - ETA: 0s - loss: 7.3729 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n15/36 [===========>..................] - ETA: 0s - loss: 7.2909 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n22/36 [=================>............] - ETA: 0s - loss: 7.1942 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n29/36 [=======================>......] - ETA: 0s - loss: 7.1872 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - ETA: 0s - loss: 7.1652 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 7.1652 - accuracy: 0.0000e+00 - val_loss: 7.0487 - val_accuracy: 0.0000e+00\nEpoch 9/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.0805 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.1555 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n17/36 [=============>................] - ETA: 0s - loss: 7.1045 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 7.1200 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 7.1492 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1696 - accuracy: 0.0000e+00 - val_loss: 7.0235 - val_accuracy: 0.0000e+00\nEpoch 10/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.7992 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.2879 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 7.2725 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n25/36 [===================>..........] - ETA: 0s - loss: 7.2192 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n32/36 [=========================>....] - ETA: 0s - loss: 7.1765 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1828 - accuracy: 0.0000e+00 - val_loss: 6.9451 - val_accuracy: 0.0000e+00\nEpoch 11/50\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.1635 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.0933 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 7.1256 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n24/36 [===================>..........] - ETA: 0s - loss: 7.1214 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n32/36 [=========================>....] - ETA: 0s - loss: 7.1861 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 7.1837 - accuracy: 0.0000e+00 - val_loss: 7.0367 - val_accuracy: 0.0000e+00\nEpoch 12/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 6.7612 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 8/36 [=====>........................] - ETA: 0s - loss: 7.1166 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n16/36 [============>.................] - ETA: 0s - loss: 7.1399 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n23/36 [==================>...........] - ETA: 0s - loss: 7.1707 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 7.2075 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1939 - accuracy: 0.0000e+00 - val_loss: 7.0558 - val_accuracy: 0.0000e+00\nEpoch 13/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.5765 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n 9/36 [======>.......................] - ETA: 0s - loss: 7.2162 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n16/36 [============>.................] - ETA: 0s - loss: 7.1651 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n23/36 [==================>...........] - ETA: 0s - loss: 7.1472 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 7.1299 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1836 - accuracy: 0.0000e+00 - val_loss: 7.0271 - val_accuracy: 0.0000e+00\nEpoch 14/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.3232 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.2814 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 7.3278 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n25/36 [===================>..........] - ETA: 0s - loss: 7.2694 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n33/36 [==========================>...] - ETA: 0s - loss: 7.1727 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1843 - accuracy: 0.0000e+00 - val_loss: 7.0294 - val_accuracy: 0.0000e+00\nEpoch 15/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 6.8474 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 7/36 [====>.........................] - ETA: 0s - loss: 7.0609 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n14/36 [==========>...................] - ETA: 0s - loss: 7.3006 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n21/36 [================>.............] - ETA: 0s - loss: 7.1957 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n28/36 [======================>.......] - ETA: 0s - loss: 7.1760 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n35/36 [============================>.] - ETA: 0s - loss: 7.1622 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 7.1728 - accuracy: 0.0000e+00 - val_loss: 6.9867 - val_accuracy: 0.0000e+00\nEpoch 16/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.5857 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.2691 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 7.2001 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n26/36 [====================>.........] - ETA: 0s - loss: 7.1460 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n34/36 [===========================>..] - ETA: 0s - loss: 7.1953 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 7.1883 - accuracy: 0.0000e+00 - val_loss: 7.0532 - val_accuracy: 0.0000e+00\nEpoch 17/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.5430 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.2545 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n18/36 [==============>...............] - ETA: 0s - loss: 7.2289 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n26/36 [====================>.........] - ETA: 0s - loss: 7.2447 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n34/36 [===========================>..] - ETA: 0s - loss: 7.1892 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 7.1814 - accuracy: 0.0000e+00 - val_loss: 7.0602 - val_accuracy: 0.0000e+00\nEpoch 18/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.8417 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.0924 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n17/36 [=============>................] - ETA: 0s - loss: 7.1593 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n20/36 [===============>..............] - ETA: 0s - loss: 7.1623 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n28/36 [======================>.......] - ETA: 0s - loss: 7.1980 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - ETA: 0s - loss: 7.1710 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 11ms/step - loss: 7.1710 - accuracy: 0.0000e+00 - val_loss: 7.0418 - val_accuracy: 0.0000e+00\nEpoch 19/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.0178 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.1858 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n16/36 [============>.................] - ETA: 0s - loss: 7.2300 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 7.2590 - accuracy: 0.0000e+00\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n32/36 [=========================>....] - ETA: 0s - loss: 7.1779 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1849 - accuracy: 0.0000e+00 - val_loss: 7.0336 - val_accuracy: 0.0000e+00\nEpoch 20/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.1568 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n 9/36 [======>.......................] - ETA: 0s - loss: 7.0219 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n17/36 [=============>................] - ETA: 0s - loss: 7.1778 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n25/36 [===================>..........] - ETA: 0s - loss: 7.1469 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n32/36 [=========================>....] - ETA: 0s - loss: 7.1647 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 7.1716 - accuracy: 0.0000e+00 - val_loss: 7.0618 - val_accuracy: 0.0000e+00\nEpoch 21/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.4421 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.2193 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n17/36 [=============>................] - ETA: 0s - loss: 7.1792 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 7.1438 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n31/36 [========================>.....] - ETA: 0s - loss: 7.1893 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 9ms/step - loss: 7.1682 - accuracy: 0.0000e+00 - val_loss: 7.0416 - val_accuracy: 0.0000e+00\nEpoch 22/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.5468 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.1620 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n17/36 [=============>................] - ETA: 0s - loss: 7.0290 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n25/36 [===================>..........] - ETA: 0s - loss: 7.0830 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n32/36 [=========================>....] - ETA: 0s - loss: 7.1298 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1788 - accuracy: 0.0000e+00 - val_loss: 7.0485 - val_accuracy: 0.0000e+00\nEpoch 23/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 6.7645 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, \n 9/36 [======>.......................] - ETA: 0s - loss: 7.1966 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n16/36 [============>.................] - ETA: 0s - loss: 7.0808 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n23/36 [==================>...........] - ETA: 0s - loss: 7.1263 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n30/36 [========================>.....] - ETA: 0s - loss: 7.1543 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1870 - accuracy: 0.0000e+00 - val_loss: 7.0345 - val_accuracy: 0.0000e+00\nEpoch 24/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 7.4550 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.2661 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 7.3297 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n25/36 [===================>..........] - ETA: 0s - loss: 7.2445 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n32/36 [=========================>....] - ETA: 0s - loss: 7.1688 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1710 - accuracy: 0.0000e+00 - val_loss: 7.0368 - val_accuracy: 0.0000e+00\nEpoch 25/50\n(100, 3)\n(100, 3)\n 1/36 [..............................] - ETA: 0s - loss: 6.7612 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n 9/36 [======>.......................] - ETA: 0s - loss: 7.0502 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n17/36 [=============>................] - ETA: 0s - loss: 7.1645 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n24/36 [===================>..........] - ETA: 0s - loss: 7.1838 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n32/36 [=========================>....] - ETA: 0s - loss: 7.1899 - accuracy: 0.0000e+00(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n(100, 3)\n36/36 [==============================] - 0s 10ms/step - loss: 7.1811 - accuracy: 0.0000e+00 - val_loss: 7.0587 - val_accuracy: 0.0000e+00\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a22709b5c2f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m     14\u001b[0m   \u001b[0mmy_training_batch_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1084\u001b[0m       data_handler._initial_epoch = (  # pylint: disable=protected-access\n\u001b[0;32m   1085\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[1;32m-> 1086\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1087\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m           \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_recreate_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m           \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[0;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    700\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;31m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \", \".join(graph_rewrites))\n\u001b[0;32m    385\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         dataset = _OptimizeDataset(dataset, graph_rewrites,\n\u001b[0m\u001b[0;32m    387\u001b[0m                                    graph_rewrite_configs)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, optimizations, optimization_configs)\u001b[0m\n\u001b[0;32m   4394\u001b[0m     self._optimizations = ops.convert_to_tensor(\n\u001b[0;32m   4395\u001b[0m         optimizations, dtype=dtypes.string, name=\"optimizations\")\n\u001b[1;32m-> 4396\u001b[1;33m     variant_tensor = gen_dataset_ops.optimize_dataset(\n\u001b[0m\u001b[0;32m   4397\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4398\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Learning\\LearningExamples\\LearningRepository\\environment\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset\u001b[1;34m(input_dataset, optimizations, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[0;32m   3941\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3943\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3944\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OptimizeDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3945\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=34)\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "my_training_batch_generator = My_Custom_Generator(X_train, y_train, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(X_test, y_test, batch_size)\n",
    "\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  my_training_batch_generator,\n",
    "  epochs=num_epochs,\n",
    "  validation_data = my_validation_batch_generator,\n",
    "  validation_steps=len(my_validation_batch_generator)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}