{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.4 64-bit ('environment')",
   "display_name": "Python 3.8.4 64-bit ('environment')",
   "metadata": {
    "interpreter": {
     "hash": "c7078795451516990b5063858187451c7430e7cd38ad966d2507248d462c4472"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcFace: Additive Angular Margin Loss for Deep Face Recognition.  \n",
    "[click here](https://arxiv.org/abs/1801.07698) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, X, labels, batch_size) :\n",
    "    self.X = X\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    self.shuffle = True\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def __iter__(self):\n",
    "    \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "    for item in (self[i] for i in range(len(self))):\n",
    "      yield item  \n",
    "    \n",
    "  def __len__(self) :\n",
    "    #self.on_epoch_end()\n",
    "    result = (np.ceil(len(self.X) / float(self.batch_size))).astype(np.int)\n",
    "    return result\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indexes = np.arange(len(self.labels))\n",
    "    if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)\n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "    batch_x = [self.X[k] for k in indexes]\n",
    "    batch_y = [self.labels[k] for k in indexes] \n",
    "    X = np.array(batch_x, dtype=np.int32)\n",
    "    Y = np.array(batch_y)\n",
    "    #print(Y.shape)\n",
    "    X = np.concatenate((X, Y), axis=1)\n",
    "     \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "class My_Custom_GeneratorURLs(tf.keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, image_filenames, labels, batch_size, height, width, num_channels = 3) :\n",
    "    self.image_filenames = image_filenames\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    self.shuffle = True\n",
    "    self.on_epoch_end()\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    self.num_channels = num_channels\n",
    "\n",
    "  def __iter__(self):\n",
    "    \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "    for item in (self[i] for i in range(len(self))):\n",
    "      yield item  \n",
    "    \n",
    "  def __len__(self) :\n",
    "    #self.on_epoch_end()\n",
    "    result = (np.floor(len(self.image_filenames) / float(self.batch_size))).astype(np.int)  # do not  use ceil  because the histogram don know\n",
    "    return result\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indexes = np.arange(len(self.labels))\n",
    "    if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)\n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    #global height_reshaped, width_reshaped\n",
    "    indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "    b_size = len(indexes)\n",
    "\n",
    "    batch_x = [self.image_filenames[k] for k in indexes] \n",
    "    batch_y = [self.labels[k] for k in indexes]\n",
    "    #  255.0 * resize(imread(str(file_name)), (height_reshaped, width_reshaped, 3))\n",
    "    X = np.array([ 255.0 * resize(imread(str(file_name)), (self.height, self.width, 3))     #\n",
    "               for file_name in batch_x], dtype=np.int32)\n",
    "    \n",
    "    Y = np.array(batch_y)\n",
    "    X = np.reshape(X, (b_size, self.num_channels * self.height * self.width))\n",
    "\n",
    "    X = np.concatenate((X, Y), axis=1)\n",
    "    return X, Y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFace(layers.Layer):\n",
    "    def __init__(self, n_classes=10, s=30.0, m=0.50, regularizer=None, **kwargs):\n",
    "        super(ArcFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = tf.keras.regularizers.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcFace, self).build(input_shape)\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[-1], self.n_classes),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True,\n",
    "                                regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, x, y):\n",
    "        #x, y = inputs\n",
    "        c = K.shape(x)[-1]\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        # add margin\n",
    "        # clip logits to prevent zero division when backward\n",
    "        theta = tf.acos(K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        # sin = tf.sqrt(1 - logits**2)\n",
    "        # cos_m = tf.cos(logits)\n",
    "        # sin_m = tf.sin(logits)\n",
    "        # target_logits = logits * cos_m - sin * sin_m\n",
    "        #\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        # feature re-scale\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_patterns = 2000\n",
    "num_features = 2\n",
    "mu, sigma = 0, 0.5\n",
    "num_classes = 2\n",
    "num_hidden_neurons = 4\n",
    "Xred = np.random.normal(mu, sigma, (num_patterns, num_features)) + np.array([1,1])\n",
    "Yred = np.zeros(num_patterns, dtype=int)\n",
    "Xblue = np.random.normal(mu, sigma, (num_patterns, num_features)) + np.array([-1,-1])\n",
    "Yblue = np.ones(num_patterns, dtype=int)\n",
    "X = np.concatenate((Xred, Xblue), axis=0)\n",
    "Y = np.concatenate((Yred, Yblue), axis=0)\n",
    "Y = np.reshape(Y, (-1,1))\n",
    "\n",
    "Y_hot = np.squeeze(np.eye(num_classes)[Y.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(num_features+num_classes))\n",
    "real_input = inputs[:,0:num_features]\n",
    "real_output = inputs[:,num_features: num_features+num_classes]\n",
    "output_1 = layers.Dense(4, activation='relu')(real_input)\n",
    "output_2 = layers.Dense(4, activation='relu')(output_1)\n",
    "predictions = ArcFace(num_classes)(output_2, real_output)  \n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 8.7661 - accuracy: 0.2553 - val_loss: 8.4027 - val_accuracy: 0.3575\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.7645 - accuracy: 0.4472 - val_loss: 7.9814 - val_accuracy: 0.4775\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6398 - accuracy: 0.4986 - val_loss: 7.9784 - val_accuracy: 0.4775\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6384 - accuracy: 0.4986 - val_loss: 7.9779 - val_accuracy: 0.4775\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.6378 - accuracy: 0.4989 - val_loss: 7.9776 - val_accuracy: 0.4775\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.6374 - accuracy: 0.4989 - val_loss: 7.9773 - val_accuracy: 0.4775\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6370 - accuracy: 0.5014 - val_loss: 7.9770 - val_accuracy: 0.4800\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6367 - accuracy: 0.5022 - val_loss: 7.9768 - val_accuracy: 0.4800\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6364 - accuracy: 0.5022 - val_loss: 7.9766 - val_accuracy: 0.4800\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6362 - accuracy: 0.5022 - val_loss: 7.9765 - val_accuracy: 0.4800\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6360 - accuracy: 0.5022 - val_loss: 7.9763 - val_accuracy: 0.4800\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6358 - accuracy: 0.5022 - val_loss: 7.9762 - val_accuracy: 0.4800\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6357 - accuracy: 0.5022 - val_loss: 7.9761 - val_accuracy: 0.4800\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6355 - accuracy: 0.5022 - val_loss: 7.9760 - val_accuracy: 0.4800\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6354 - accuracy: 0.5022 - val_loss: 7.9760 - val_accuracy: 0.4800\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6353 - accuracy: 0.5022 - val_loss: 7.9759 - val_accuracy: 0.4800\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6352 - accuracy: 0.5022 - val_loss: 7.9758 - val_accuracy: 0.4800\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6352 - accuracy: 0.5022 - val_loss: 7.9758 - val_accuracy: 0.4800\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6351 - accuracy: 0.5022 - val_loss: 7.9757 - val_accuracy: 0.4800\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6350 - accuracy: 0.5022 - val_loss: 7.9757 - val_accuracy: 0.4800\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.6350 - accuracy: 0.5022 - val_loss: 7.9757 - val_accuracy: 0.4800\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6349 - accuracy: 0.5022 - val_loss: 7.9756 - val_accuracy: 0.4800\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6349 - accuracy: 0.5022 - val_loss: 7.9756 - val_accuracy: 0.4800\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6349 - accuracy: 0.5022 - val_loss: 7.9756 - val_accuracy: 0.4800\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6348 - accuracy: 0.5022 - val_loss: 7.9756 - val_accuracy: 0.4800\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6348 - accuracy: 0.5022 - val_loss: 7.9755 - val_accuracy: 0.4800\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6348 - accuracy: 0.5022 - val_loss: 7.9755 - val_accuracy: 0.4800\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6348 - accuracy: 0.5022 - val_loss: 7.9755 - val_accuracy: 0.4800\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6347 - accuracy: 0.5022 - val_loss: 7.9755 - val_accuracy: 0.4800\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6347 - accuracy: 0.5022 - val_loss: 7.9755 - val_accuracy: 0.4800\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6347 - accuracy: 0.5022 - val_loss: 7.9755 - val_accuracy: 0.4800\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6347 - accuracy: 0.5022 - val_loss: 7.9755 - val_accuracy: 0.4800\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6347 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6347 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6347 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 7.6346 - accuracy: 0.5022 - val_loss: 7.9754 - val_accuracy: 0.4800\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dbe6c44f10>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_hot, test_size=0.1, random_state=34)\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "my_training_batch_generator = My_Custom_Generator(X_train, y_train, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(X_test, y_test, batch_size)\n",
    "\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  my_training_batch_generator,\n",
    "  epochs=num_epochs,\n",
    "  validation_data = my_validation_batch_generator,\n",
    "  validation_steps=len(my_validation_batch_generator)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_texts = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes_texts)\n",
    "height = 32\n",
    "width = 32\n",
    "num_channels = 3\n",
    "batch_size = 8\n",
    "X_train = list(((os.path.abspath('./../../assets/cifar10small/'+ name+str(i+1)+'.png')) for name in classes_texts for i in range(7)))\n",
    "X_test  = list(((os.path.abspath('./../../assets/cifar10small/'+ name+str(7+i+1)+'.png')) for name in classes_texts for i in range(3))) \n",
    "y_train = list((j for j in range(10) for i in range(7)))\n",
    "y_test = list((j for j in range(10) for i in range(3)))\n",
    "\n",
    "y_train_hot = np.squeeze(np.eye(num_classes)[np.array(y_train).reshape(-1)])\n",
    "y_test_hot = np.squeeze(np.eye(num_classes)[np.array(y_test).reshape(-1)])\n",
    "\n",
    "my_training_batch_generator_cifar = My_Custom_GeneratorURLs(X_train, y_train_hot, batch_size, height, width)\n",
    "my_validation_batch_generator_cifar = My_Custom_GeneratorURLs(X_test, y_test_hot, batch_size, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = height * width*  num_channels\n",
    "inputs = tf.keras.Input(shape=(num_features + num_classes))\n",
    "\n",
    "#flatten_images = flatten_images.astype('float32')\n",
    "flatten_images = (inputs[:, 0:num_features] / 255.0) \n",
    "# you can reshape output_1 and convert it in the original dataset\n",
    "#flatten_images = tf.reshape(flatten_images, [-1, height, width, num_channels])\n",
    "output_1 = layers.Dense(14, activation='relu')(flatten_images)\n",
    "output_2 = layers.Dense(14, activation='relu')(output_1)\n",
    "\n",
    "# you can compare how faster is the ArcFace decreasing the loss\n",
    "#predictions = layers.Dense(num_classes, activation='softmax')(output_2)\n",
    "predictions = ArcFace(num_classes)(output_2, inputs[:, num_features: num_features + num_classes])  \n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================] - 1s 85ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 27.2458 - val_accuracy: 0.0417\n",
      "Epoch 363/500\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 28.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 27.4743 - val_accuracy: 0.0417\n",
      "Epoch 365/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 27.0891 - val_accuracy: 0.0417\n",
      "Epoch 366/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 26.6938 - val_accuracy: 0.0417\n",
      "Epoch 367/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 26.3949 - val_accuracy: 0.0417\n",
      "Epoch 368/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 27.3057 - val_accuracy: 0.0417\n",
      "Epoch 369/500\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 27.4626 - val_accuracy: 0.0417\n",
      "Epoch 370/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 28.8153 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 28.2329 - val_accuracy: 0.0417\n",
      "Epoch 372/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 27.0274 - val_accuracy: 0.0417\n",
      "Epoch 373/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 27.2651 - val_accuracy: 0.0417\n",
      "Epoch 374/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 28.7983 - val_accuracy: 0.0417\n",
      "Epoch 375/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 28.1407 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 26.0730 - val_accuracy: 0.0417\n",
      "Epoch 377/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 27.7368 - val_accuracy: 0.0417\n",
      "Epoch 378/500\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 26.6906 - val_accuracy: 0.0417\n",
      "Epoch 379/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 26.1620 - val_accuracy: 0.0417\n",
      "Epoch 380/500\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 27.3557 - val_accuracy: 0.0417\n",
      "Epoch 381/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 26.7815 - val_accuracy: 0.0417\n",
      "Epoch 382/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 27.5766 - val_accuracy: 0.0417\n",
      "Epoch 383/500\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 26.9940 - val_accuracy: 0.0417\n",
      "Epoch 384/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 26.3141 - val_accuracy: 0.0417\n",
      "Epoch 385/500\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 27.5883 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 27.4319 - val_accuracy: 0.0417\n",
      "Epoch 387/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 28.7982 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 28.6490 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 28.5036 - val_accuracy: 0.0417\n",
      "Epoch 390/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 27.8078 - val_accuracy: 0.0417\n",
      "Epoch 391/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 27.1463 - val_accuracy: 0.0417\n",
      "Epoch 392/500\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 27.2182 - val_accuracy: 0.0417\n",
      "Epoch 393/500\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 27.3439 - val_accuracy: 0.0417\n",
      "Epoch 394/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 27.0187 - val_accuracy: 0.0417\n",
      "Epoch 395/500\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 26.1871 - val_accuracy: 0.0417\n",
      "Epoch 396/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 28.3225 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 28.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 27.9944 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 27.8614 - val_accuracy: 0.0417\n",
      "Epoch 400/500\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 28.2786 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 27.4015 - val_accuracy: 0.0417\n",
      "Epoch 402/500\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 27.2621 - val_accuracy: 0.0417\n",
      "Epoch 403/500\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 26.2968 - val_accuracy: 0.0417\n",
      "Epoch 404/500\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 28.9643 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 26.7616 - val_accuracy: 0.0417\n",
      "Epoch 406/500\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 28.7152 - val_accuracy: 0.0417\n",
      "Epoch 407/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 27.6189 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 28.1241 - val_accuracy: 0.0417\n",
      "Epoch 409/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 27.8777 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 27.0927 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 26.4745 - val_accuracy: 0.0417\n",
      "Epoch 412/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 27.2617 - val_accuracy: 0.0417\n",
      "Epoch 413/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 30.0878 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 27.5462 - val_accuracy: 0.0417\n",
      "Epoch 415/500\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 29.0394 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 27.1225 - val_accuracy: 0.0417\n",
      "Epoch 417/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 26.3940 - val_accuracy: 0.0417\n",
      "Epoch 418/500\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 28.7463 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 27.0382 - val_accuracy: 0.0417\n",
      "Epoch 420/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 26.2328 - val_accuracy: 0.0417\n",
      "Epoch 421/500\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 27.8317 - val_accuracy: 0.0417\n",
      "Epoch 422/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 26.9611 - val_accuracy: 0.0417\n",
      "Epoch 423/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 26.6657 - val_accuracy: 0.0417\n",
      "Epoch 424/500\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 27.3224 - val_accuracy: 0.0417\n",
      "Epoch 425/500\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 26.6406 - val_accuracy: 0.0417\n",
      "Epoch 426/500\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 27.0506 - val_accuracy: 0.0417\n",
      "Epoch 427/500\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 27.6180 - val_accuracy: 0.0417\n",
      "Epoch 428/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 27.5526 - val_accuracy: 0.0417\n",
      "Epoch 429/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 29.8137 - val_accuracy: 0.0417\n",
      "Epoch 430/500\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 28.6696 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 29.0793 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 26.4972 - val_accuracy: 0.0417\n",
      "Epoch 433/500\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 27.8284 - val_accuracy: 0.0417\n",
      "Epoch 434/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 28.4991 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 26.3055 - val_accuracy: 0.0417\n",
      "Epoch 436/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 27.8663 - val_accuracy: 0.0417\n",
      "Epoch 437/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 29.5386 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 29.6750 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 26.8163 - val_accuracy: 0.0417\n",
      "Epoch 440/500\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 28.5636 - val_accuracy: 0.0417\n",
      "Epoch 441/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 26.4026 - val_accuracy: 0.0417\n",
      "Epoch 442/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 26.2980 - val_accuracy: 0.0417\n",
      "Epoch 443/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 27.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 29.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 26.1460 - val_accuracy: 0.0417\n",
      "Epoch 446/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 27.7658 - val_accuracy: 0.0417\n",
      "Epoch 447/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 27.9834 - val_accuracy: 0.0417\n",
      "Epoch 448/500\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 26.7858 - val_accuracy: 0.0417\n",
      "Epoch 449/500\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 26.3488 - val_accuracy: 0.0417\n",
      "Epoch 450/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 28.2309 - val_accuracy: 0.0417\n",
      "Epoch 451/500\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 27.9820 - val_accuracy: 0.0417\n",
      "Epoch 452/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 26.4835 - val_accuracy: 0.0417\n",
      "Epoch 453/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 27.5647 - val_accuracy: 0.0417\n",
      "Epoch 454/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 28.5797 - val_accuracy: 0.0417\n",
      "Epoch 455/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 28.0162 - val_accuracy: 0.0417\n",
      "Epoch 456/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 27.8219 - val_accuracy: 0.0417\n",
      "Epoch 457/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 27.2338 - val_accuracy: 0.0417\n",
      "Epoch 458/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 25.7641 - val_accuracy: 0.0417\n",
      "Epoch 459/500\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 26.0866 - val_accuracy: 0.0417\n",
      "Epoch 460/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 27.6773 - val_accuracy: 0.0417\n",
      "Epoch 461/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 26.8965 - val_accuracy: 0.0417\n",
      "Epoch 462/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 27.0717 - val_accuracy: 0.0417\n",
      "Epoch 463/500\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 28.7916 - val_accuracy: 0.0417\n",
      "Epoch 464/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 29.1353 - val_accuracy: 0.0417\n",
      "Epoch 465/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 27.5167 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 26.2510 - val_accuracy: 0.0417\n",
      "Epoch 467/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 27.7983 - val_accuracy: 0.0417\n",
      "Epoch 468/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 27.5648 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 26.1333 - val_accuracy: 0.0417\n",
      "Epoch 470/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 26.6287 - val_accuracy: 0.0417\n",
      "Epoch 471/500\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 27.4452 - val_accuracy: 0.0417\n",
      "Epoch 472/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 26.2649 - val_accuracy: 0.0417\n",
      "Epoch 473/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 30.0598 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 26.2982 - val_accuracy: 0.0417\n",
      "Epoch 475/500\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 27.2700 - val_accuracy: 0.0417\n",
      "Epoch 476/500\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 26.9922 - val_accuracy: 0.0417\n",
      "Epoch 477/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 27.2414 - val_accuracy: 0.0417\n",
      "Epoch 478/500\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 27.8067 - val_accuracy: 0.0417\n",
      "Epoch 479/500\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 28.3277 - val_accuracy: 0.0417\n",
      "Epoch 480/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 28.8338 - val_accuracy: 0.0417\n",
      "Epoch 481/500\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 27.4574 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 29.0278 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 26.2435 - val_accuracy: 0.0417\n",
      "Epoch 484/500\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 27.9693 - val_accuracy: 0.0417\n",
      "Epoch 485/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 28.4999 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 29.1290 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 28.8268 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 28.2454 - val_accuracy: 0.0417\n",
      "Epoch 489/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 27.4865 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 27.4502 - val_accuracy: 0.0417\n",
      "Epoch 491/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 27.4970 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 27.9962 - val_accuracy: 0.0417\n",
      "Epoch 493/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 27.4374 - val_accuracy: 0.0417\n",
      "Epoch 494/500\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 27.5303 - val_accuracy: 0.0417\n",
      "Epoch 495/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 28.6602 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 28.1329 - val_accuracy: 0.0417\n",
      "Epoch 497/500\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 26.0793 - val_accuracy: 0.0417\n",
      "Epoch 498/500\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 30.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 26.8128 - val_accuracy: 0.0417\n",
      "Epoch 500/500\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 29.9753 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2db926acd00>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  my_training_batch_generator_cifar,\n",
    "  epochs=num_epochs,\n",
    "  validation_data = my_validation_batch_generator_cifar  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "height = 32\n",
    "width = 32\n",
    "num_features = height * width*  num_channels\n",
    "my_training_batch_generator_cifar = My_Custom_GeneratorURLs(X_train, y_train_hot, batch_size, height, width)\n",
    "my_validation_batch_generator_cifar = My_Custom_GeneratorURLs(X_test, y_test_hot, batch_size, height, width)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(num_features + num_classes))\n",
    "flatten_images = inputs[:, 0:num_features]/ 255.0\n",
    "# you can reshape output_1 and convert it in the original dataset\n",
    "real_input = tf.reshape(flatten_images, [-1, height, width, num_channels])\n",
    "\n",
    "resnet_output = tf.keras.applications.ResNet152V2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=( height, width, num_channels),\n",
    "    pooling=None,\n",
    "    classes=num_classes,\n",
    "    classifier_activation=None,\n",
    ")(real_input)\n",
    "\n",
    "desired_output = inputs[:, num_features: num_features + num_classes]\n",
    "# you can compare how faster is the ArcFace decreasing the loss\n",
    "#predictions = layers.Dense(num_classes, activation='softmax')(desired_output)\n",
    "predictions = ArcFace(num_classes)(resnet_output, desired_output)  \n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===] - 17s 2s/step - loss: 4.6178 - accuracy: 0.6094\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.8447 - accuracy: 0.4844\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 18s 2s/step - loss: 5.7494 - accuracy: 0.5938\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 18s 2s/step - loss: 4.4486 - accuracy: 0.5469\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.9684 - accuracy: 0.5469\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.9598 - accuracy: 0.4531\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.4725 - accuracy: 0.5938\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 14s 2s/step - loss: 4.9294 - accuracy: 0.5312\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 5.0755 - accuracy: 0.5312\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 4.9250 - accuracy: 0.4844\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.2976 - accuracy: 0.7031\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.2937 - accuracy: 0.5469\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.0734 - accuracy: 0.5938\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 4.5912 - accuracy: 0.6875\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.4915 - accuracy: 0.5781\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 3.9338 - accuracy: 0.7188\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.2656 - accuracy: 0.6562\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 18s 2s/step - loss: 5.2197 - accuracy: 0.5781\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 4.5122 - accuracy: 0.5625\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.6295 - accuracy: 0.5625\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.3335 - accuracy: 0.6250\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 18s 2s/step - loss: 5.0346 - accuracy: 0.6406\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.1942 - accuracy: 0.6250\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 13s 2s/step - loss: 4.1367 - accuracy: 0.5938\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 4.5579 - accuracy: 0.5938\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.8785 - accuracy: 0.6562\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.1138 - accuracy: 0.5625\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.7256 - accuracy: 0.6875\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.6506 - accuracy: 0.5938\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 5.3035 - accuracy: 0.5938\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.6936 - accuracy: 0.7031\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.2882 - accuracy: 0.6562\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.6394 - accuracy: 0.6719\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.4042 - accuracy: 0.6719\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.5829 - accuracy: 0.7031\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.0714 - accuracy: 0.6875\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.6861 - accuracy: 0.5625\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.4583 - accuracy: 0.7656\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.7728 - accuracy: 0.6875\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 3.4323 - accuracy: 0.7344\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.7860 - accuracy: 0.7500\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.9586 - accuracy: 0.6094\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.6555 - accuracy: 0.6875\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.9744 - accuracy: 0.6094\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.2442 - accuracy: 0.7344\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.3725 - accuracy: 0.7656\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 11s 1s/step - loss: 3.9148 - accuracy: 0.7188\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 3.0572 - accuracy: 0.7188\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.3513 - accuracy: 0.5156\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 6.1257 - accuracy: 0.5781\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 13s 2s/step - loss: 4.9644 - accuracy: 0.6719\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 5.7356 - accuracy: 0.6094\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.3511 - accuracy: 0.7031\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.6063 - accuracy: 0.5938\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 5.4171 - accuracy: 0.5781\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 4.1136 - accuracy: 0.5938\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 4.2597 - accuracy: 0.6719\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 4.2652 - accuracy: 0.6250\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.3516 - accuracy: 0.7344\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.9591 - accuracy: 0.6719\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 4.2631 - accuracy: 0.6875\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.8824 - accuracy: 0.7188\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.9692 - accuracy: 0.7344\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 3.6636 - accuracy: 0.6875\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 4.0477 - accuracy: 0.6562\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.9011 - accuracy: 0.6250\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.7727 - accuracy: 0.7500\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 14s 2s/step - loss: 2.6481 - accuracy: 0.7500\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.7352 - accuracy: 0.7188\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 3.3891 - accuracy: 0.6875\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.3340 - accuracy: 0.7031\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 3.1825 - accuracy: 0.7031\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.6585 - accuracy: 0.7344\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 2.5517 - accuracy: 0.7188\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 2.9679 - accuracy: 0.6094\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.8102 - accuracy: 0.7188\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 2.1071 - accuracy: 0.7969\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.8804 - accuracy: 0.7188\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.4467 - accuracy: 0.7344\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.1872 - accuracy: 0.7812\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.1034 - accuracy: 0.7344\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 3.0578 - accuracy: 0.7812\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.2128 - accuracy: 0.6875\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 2.1217 - accuracy: 0.8594\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.8756 - accuracy: 0.6406\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 2.8057 - accuracy: 0.7656\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.7044 - accuracy: 0.7969\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.5534 - accuracy: 0.7344\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.9316 - accuracy: 0.7812\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.7588 - accuracy: 0.8125\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.2000 - accuracy: 0.8438\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.9632 - accuracy: 0.7344\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.2563 - accuracy: 0.7031\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.2710 - accuracy: 0.8125\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.0497 - accuracy: 0.6562\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.0545 - accuracy: 0.8125\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.7724 - accuracy: 0.7344\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 3.2816 - accuracy: 0.7031\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.0022 - accuracy: 0.7812\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.6989 - accuracy: 0.7969\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 2.9256 - accuracy: 0.7812\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 4.1101 - accuracy: 0.6719\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 2.8778 - accuracy: 0.7969\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.6768 - accuracy: 0.7344\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 13s 2s/step - loss: 2.1159 - accuracy: 0.8125\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 2.0498 - accuracy: 0.8438\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.2826 - accuracy: 0.7969\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.5694 - accuracy: 0.7812\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.4322 - accuracy: 0.9062\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.9628 - accuracy: 0.8750\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.1943 - accuracy: 0.7969\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.9667 - accuracy: 0.8438\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.8596 - accuracy: 0.9219\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.2603 - accuracy: 0.8594\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.8302 - accuracy: 0.8125\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.1788 - accuracy: 0.8594\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.6649 - accuracy: 0.8594\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.5312 - accuracy: 0.8281\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.4409 - accuracy: 0.8125\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.1193 - accuracy: 0.8594\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.0031 - accuracy: 0.8125\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.3862 - accuracy: 0.8438\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.3916 - accuracy: 0.9062\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.0755 - accuracy: 0.8750\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.0257 - accuracy: 0.8281\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.0965 - accuracy: 0.8125\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.2582 - accuracy: 0.8906\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.5380 - accuracy: 0.9219\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.8947 - accuracy: 0.8906\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.6987 - accuracy: 0.9219\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.3422 - accuracy: 0.8594\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.4722 - accuracy: 0.8281\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.7854 - accuracy: 0.9062\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.8282 - accuracy: 0.9062\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.4429 - accuracy: 0.8750\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.1288 - accuracy: 0.8594\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.0911 - accuracy: 0.8438\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.1959 - accuracy: 0.8125\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.6446 - accuracy: 0.9062\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.5153 - accuracy: 0.9219\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.8229 - accuracy: 0.9219\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.6404 - accuracy: 0.9375\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3146 - accuracy: 0.9531\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.1350 - accuracy: 0.8906\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.5328 - accuracy: 0.9531\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.3670 - accuracy: 0.8906\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.5782 - accuracy: 0.8750\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.7743 - accuracy: 0.8906\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.8661 - accuracy: 0.9062\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.8663 - accuracy: 0.8906\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.2747 - accuracy: 0.9375\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.2222 - accuracy: 0.8750\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.7340 - accuracy: 0.8594\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.1183 - accuracy: 0.8750\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.1959 - accuracy: 0.9219\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.5904 - accuracy: 0.8281\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.4295 - accuracy: 0.9375\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.1786 - accuracy: 0.9688\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.5807 - accuracy: 0.9531\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.1320 - accuracy: 0.9531\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.6739 - accuracy: 0.9219\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.6776 - accuracy: 0.9062\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.1601 - accuracy: 0.9375\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.6762 - accuracy: 0.9219\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.7252 - accuracy: 0.8906\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.1185 - accuracy: 0.9688\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.5549 - accuracy: 0.8438\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.1472 - accuracy: 0.8906\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.6046 - accuracy: 0.9375\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.4347 - accuracy: 0.9062\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.5476 - accuracy: 0.9062\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.9743 - accuracy: 0.9531\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.4757 - accuracy: 0.9062\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.6714 - accuracy: 0.9219\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.8283 - accuracy: 0.9219\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 18s 2s/step - loss: 1.6557 - accuracy: 0.8906\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 18s 2s/step - loss: 0.4298 - accuracy: 0.9062\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.0663 - accuracy: 0.9688\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.1326 - accuracy: 0.9531\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.3461 - accuracy: 0.9219\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.2662 - accuracy: 0.8906\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.6222 - accuracy: 0.9688\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.3486 - accuracy: 0.9219\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.7640 - accuracy: 0.9219\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2013 - accuracy: 0.9531\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.2231 - accuracy: 0.8750\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.2470 - accuracy: 0.8594\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.6953 - accuracy: 0.9219\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.8362 - accuracy: 0.8438\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.2891 - accuracy: 0.9688\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.1126 - accuracy: 0.7656\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.0525 - accuracy: 0.8906\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 2.0445 - accuracy: 0.7812\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4012 - accuracy: 0.9531\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.9884 - accuracy: 0.8594\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.5312 - accuracy: 0.9375\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.1366 - accuracy: 0.9688\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.1340 - accuracy: 0.9219\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.3544 - accuracy: 0.9688\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.9470 - accuracy: 0.9375\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.1507 - accuracy: 0.9062\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.3841 - accuracy: 0.8906\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.6082 - accuracy: 0.9219\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dbab7ceaf0>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  my_training_batch_generator_cifar,\n",
    "  epochs=num_epochs,\n",
    "  validation_data = my_validation_batch_generator_cifar,\n",
    "  validation_steps=len(my_validation_batch_generator)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}