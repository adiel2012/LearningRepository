{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600143866300",
   "display_name": "Python 3.8.4 64-bit ('environment': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcFace: Additive Angular Margin Loss for Deep Face Recognition.  \n",
    "[click here](https://arxiv.org/abs/1801.07698)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, X, labels, batch_size) :\n",
    "    self.X = X\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    self.shuffle = True\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def __iter__(self):\n",
    "    \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "    for item in (self[i] for i in range(len(self))):\n",
    "      yield item  \n",
    "    \n",
    "  def __len__(self) :\n",
    "    #self.on_epoch_end()\n",
    "    result = (np.ceil(len(self.X) / float(self.batch_size))).astype(np.int)\n",
    "    return result\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indexes = np.arange(len(self.labels))\n",
    "    if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)\n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "    batch_x = [self.X[k] for k in indexes]\n",
    "    batch_y = [self.labels[k] for k in indexes] \n",
    "    X = np.array(batch_x, dtype=np.int32)\n",
    "    Y = np.array(batch_y)\n",
    "    X = np.concatenate((X, Y), axis=1)\n",
    "     \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "class My_Custom_GeneratorURLs(tf.keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, image_filenames, labels, batch_size, height, width, num_channels = 3) :\n",
    "    self.image_filenames = image_filenames\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    self.shuffle = True\n",
    "    self.on_epoch_end()\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    self.num_channels = num_channels\n",
    "\n",
    "  def __iter__(self):\n",
    "    \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "    for item in (self[i] for i in range(len(self))):\n",
    "      yield item  \n",
    "    \n",
    "  def __len__(self) :\n",
    "    #self.on_epoch_end()\n",
    "    result = (np.floor(len(self.image_filenames) / float(self.batch_size))).astype(np.int)  # do not  use ceil  because the histogram don know\n",
    "    return result\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indexes = np.arange(len(self.labels))\n",
    "    if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)\n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    #global height_reshaped, width_reshaped\n",
    "    indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "    b_size = len(indexes)\n",
    "\n",
    "    batch_x = [self.image_filenames[k] for k in indexes] \n",
    "    batch_y = [self.labels[k] for k in indexes]\n",
    "    #  255.0 * resize(imread(str(file_name)), (height_reshaped, width_reshaped, 3))\n",
    "    X = np.array([ 255.0 * resize(imread(str(file_name)), (self.height, self.width, 3))     #\n",
    "               for file_name in batch_x], dtype=np.int32)\n",
    "    \n",
    "    Y = np.array(batch_y)\n",
    "    X = np.reshape(X, (b_size, self.num_channels * self.height * self.width))\n",
    "    Y = np.reshape(Y, (-1,1))\n",
    "    X = np.concatenate((X, Y), axis=1)\n",
    "    return X, Y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFace(layers.Layer):\n",
    "    def __init__(self, n_classes=10, s=30.0, m=0.50, regularizer=None, **kwargs):\n",
    "        super(ArcFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = tf.keras.regularizers.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcFace, self).build(input_shape)\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[-1], self.n_classes),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True,\n",
    "                                regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, x, y):\n",
    "        #x, y = inputs\n",
    "        c = K.shape(x)[-1]\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        # add margin\n",
    "        # clip logits to prevent zero division when backward\n",
    "        theta = tf.acos(K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        # sin = tf.sqrt(1 - logits**2)\n",
    "        # cos_m = tf.cos(logits)\n",
    "        # sin_m = tf.sin(logits)\n",
    "        # target_logits = logits * cos_m - sin * sin_m\n",
    "        #\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        # feature re-scale\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4000, 2)\n(4000, 1)\n[[0]\n [0]\n [0]\n ...\n [1]\n [1]\n [1]]\n"
    }
   ],
   "source": [
    "num_patterns = 2000\n",
    "num_features = 2\n",
    "mu, sigma = 0, 0.5\n",
    "num_classes = 2\n",
    "num_hidden_neurons = 4\n",
    "Xred = np.random.normal(mu, sigma, (num_patterns, num_features)) + np.array([1,1])\n",
    "Yred = np.zeros(num_patterns, dtype=int)\n",
    "Xblue = np.random.normal(mu, sigma, (num_patterns, num_features)) + np.array([-1,-1])\n",
    "Yblue = np.ones(num_patterns, dtype=int)\n",
    "X = np.concatenate((Xred, Xblue), axis=0)\n",
    "Y = np.concatenate((Yred, Yblue), axis=0)\n",
    "Y = np.reshape(Y, (-1,1))\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(num_features+num_classes))\n",
    "output_1 = layers.Dense(4, activation='relu')(inputs[:,0:num_features])\n",
    "output_2 = layers.Dense(4, activation='relu')(output_1)\n",
    "predictions = ArcFace(num_classes)(output_2, inputs[:,num_features: num_features+num_classes])  \n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n36/36 [==============================] - 1s 33ms/step - loss: 1.3761 - accuracy: 0.0144 - val_loss: 0.7675 - val_accuracy: 0.0000e+00\nEpoch 2/50\n36/36 [==============================] - 0s 8ms/step - loss: 0.7044 - accuracy: 0.6111 - val_loss: 0.6955 - val_accuracy: 1.0000\nEpoch 3/50\n36/36 [==============================] - 0s 7ms/step - loss: 0.6935 - accuracy: 0.3889 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\nEpoch 4/50\n36/36 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.7500 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 5/50\n36/36 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 6/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5556 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\nEpoch 7/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.7003 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\nEpoch 8/50\n36/36 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.3556 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 9/50\n36/36 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 10/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 11/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 12/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 13/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 14/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 15/50\n36/36 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 16/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 17/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 18/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 19/50\n36/36 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 20/50\n36/36 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 21/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 22/50\n36/36 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 23/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 24/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 25/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 26/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 27/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 28/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 29/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 30/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 31/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 32/50\n23/36 [==================>...........] - ETA: 0s - loss: 0.6931 - accuracy: 1.0036/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 33/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 34/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 35/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 36/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 37/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 38/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 39/50\n26/36 [====================>.........] - ETA: 0s - loss: 0.6931 - accuracy: 1.0036/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 40/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 41/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 42/50\n36/36 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 43/50\n36/36 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 44/50\n36/36 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 45/50\n36/36 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 46/50\n36/36 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 47/50\n36/36 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 48/50\n36/36 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 49/50\n36/36 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\nEpoch 50/50\n36/36 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 1.0000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x173944f0f70>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=34)\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "my_training_batch_generator = My_Custom_Generator(X_train, y_train, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(X_test, y_test, batch_size)\n",
    "\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  my_training_batch_generator,\n",
    "  epochs=num_epochs,\n",
    "  validation_data = my_validation_batch_generator,\n",
    "  validation_steps=len(my_validation_batch_generator)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_texts = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes_texts)\n",
    "height = 32\n",
    "width = 32\n",
    "num_channels = 3\n",
    "batch_size = 8\n",
    "X_train = list(((os.path.abspath('./../../assets/cifar10small/'+ name+str(i+1)+'.png')) for name in classes_texts for i in range(7)))\n",
    "X_test  = list(((os.path.abspath('./../../assets/cifar10small/'+ name+str(7+i+1)+'.png')) for name in classes_texts for i in range(3))) \n",
    "y_train = list((j for j in range(10) for i in range(7)))\n",
    "y_test = list((j for j in range(10) for i in range(3)))\n",
    "\n",
    "my_training_batch_generator_cifar = My_Custom_GeneratorURLs(X_train, y_train, batch_size, height, width)\n",
    "my_validation_batch_generator_cifar = My_Custom_GeneratorURLs(X_test, y_test, batch_size, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = height * width*  num_channels\n",
    "inputs = tf.keras.Input(shape=(num_features + num_classes))\n",
    "flatten_images = inputs[:, 0:num_features]\n",
    "# you can reshape output_1 and convert it in the original dataset\n",
    "#flatten_images = tf.reshape(flatten_images, [-1, height, width, num_channels])\n",
    "output_1 = layers.Dense(4, activation='relu')(flatten_images)\n",
    "output_2 = layers.Dense(4, activation='relu')(output_1)\n",
    "\n",
    "# you can compare how faster is the ArcFace decreasing the loss\n",
    "#predictions = layers.Dense(num_classes, activation='softmax')(output_2)\n",
    "predictions = ArcFace(num_classes)(output_2, inputs[:, num_features: num_features + num_classes])  \n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n8/8 [==============================] - ETA: 0s - loss: 838.0089 - accuracy: 0.0000e+00WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n8/8 [==============================] - 4s 524ms/step - loss: 838.0089 - accuracy: 0.0000e+00 - val_loss: 924.9583 - val_accuracy: 0.0000e+00\nEpoch 2/50\n8/8 [==============================] - 1s 73ms/step - loss: 943.5479 - accuracy: 0.0000e+00\nEpoch 3/50\n8/8 [==============================] - 1s 64ms/step - loss: 1041.1353 - accuracy: 0.0000e+00\nEpoch 4/50\n8/8 [==============================] - 0s 54ms/step - loss: 1191.9380 - accuracy: 0.0000e+00\nEpoch 5/50\n8/8 [==============================] - 0s 47ms/step - loss: 1309.6207 - accuracy: 0.0000e+00\nEpoch 6/50\n8/8 [==============================] - 0s 48ms/step - loss: 1410.2034 - accuracy: 0.0000e+00\nEpoch 7/50\n8/8 [==============================] - 0s 37ms/step - loss: 1598.6447 - accuracy: 0.0000e+00\nEpoch 8/50\n8/8 [==============================] - 0s 36ms/step - loss: 1793.1202 - accuracy: 0.0000e+00\nEpoch 9/50\n8/8 [==============================] - 0s 36ms/step - loss: 1937.8296 - accuracy: 0.0000e+00\nEpoch 10/50\n8/8 [==============================] - 0s 31ms/step - loss: 2122.5828 - accuracy: 0.0000e+00\nEpoch 11/50\n8/8 [==============================] - 0s 33ms/step - loss: 2097.7166 - accuracy: 0.0000e+00\nEpoch 12/50\n8/8 [==============================] - 0s 34ms/step - loss: 2214.8318 - accuracy: 0.0000e+00\nEpoch 13/50\n8/8 [==============================] - 0s 36ms/step - loss: 2303.2629 - accuracy: 0.0000e+00\nEpoch 14/50\n8/8 [==============================] - 1s 72ms/step - loss: 2421.3975 - accuracy: 0.0000e+00\nEpoch 15/50\n8/8 [==============================] - 1s 69ms/step - loss: 2458.4902 - accuracy: 0.0000e+00\nEpoch 16/50\n8/8 [==============================] - 1s 72ms/step - loss: 2531.2041 - accuracy: 0.0000e+00\nEpoch 17/50\n8/8 [==============================] - 0s 55ms/step - loss: 2623.3513 - accuracy: 0.0000e+00\nEpoch 18/50\n8/8 [==============================] - 0s 47ms/step - loss: 2635.3079 - accuracy: 0.0000e+00\nEpoch 19/50\n8/8 [==============================] - 0s 60ms/step - loss: 2423.9749 - accuracy: 0.0000e+00\nEpoch 20/50\n8/8 [==============================] - 0s 54ms/step - loss: 2484.7563 - accuracy: 0.0000e+00\nEpoch 21/50\n8/8 [==============================] - 0s 49ms/step - loss: 2562.2637 - accuracy: 0.0000e+00\nEpoch 22/50\n8/8 [==============================] - 0s 53ms/step - loss: 2375.0457 - accuracy: 0.0000e+00\nEpoch 23/50\n8/8 [==============================] - 0s 48ms/step - loss: 2349.4697 - accuracy: 0.0000e+00\nEpoch 24/50\n8/8 [==============================] - 0s 39ms/step - loss: 2386.2588 - accuracy: 0.0000e+00\nEpoch 25/50\n8/8 [==============================] - 0s 51ms/step - loss: 2279.9126 - accuracy: 0.0000e+00\nEpoch 26/50\n8/8 [==============================] - 0s 51ms/step - loss: 2185.1135 - accuracy: 0.0000e+00\nEpoch 27/50\n8/8 [==============================] - 0s 52ms/step - loss: 2182.2698 - accuracy: 0.0000e+00\nEpoch 28/50\n8/8 [==============================] - 0s 55ms/step - loss: 2062.3245 - accuracy: 0.0000e+00\nEpoch 29/50\n8/8 [==============================] - 0s 47ms/step - loss: 2049.6738 - accuracy: 0.0000e+00\nEpoch 30/50\n8/8 [==============================] - 0s 54ms/step - loss: 1990.9952 - accuracy: 0.0000e+00\nEpoch 31/50\n8/8 [==============================] - 0s 45ms/step - loss: 1915.5349 - accuracy: 0.0000e+00\nEpoch 32/50\n8/8 [==============================] - 0s 43ms/step - loss: 1872.0452 - accuracy: 0.0000e+00\nEpoch 33/50\n8/8 [==============================] - 0s 38ms/step - loss: 1792.1361 - accuracy: 0.0000e+00\nEpoch 34/50\n8/8 [==============================] - 0s 38ms/step - loss: 1664.1147 - accuracy: 0.0000e+00\nEpoch 35/50\n8/8 [==============================] - 0s 38ms/step - loss: 1656.8317 - accuracy: 0.0000e+00\nEpoch 36/50\n8/8 [==============================] - 0s 44ms/step - loss: 1576.1422 - accuracy: 0.0000e+00\nEpoch 37/50\n8/8 [==============================] - 1s 68ms/step - loss: 1451.6293 - accuracy: 0.0000e+00\nEpoch 38/50\n8/8 [==============================] - 0s 60ms/step - loss: 1404.2637 - accuracy: 0.0000e+00\nEpoch 39/50\n8/8 [==============================] - 0s 51ms/step - loss: 1360.7635 - accuracy: 0.0000e+00\nEpoch 40/50\n8/8 [==============================] - 0s 49ms/step - loss: 1392.5007 - accuracy: 0.0000e+00\nEpoch 41/50\n8/8 [==============================] - 0s 50ms/step - loss: 1255.0449 - accuracy: 0.0000e+00\nEpoch 42/50\n8/8 [==============================] - 0s 47ms/step - loss: 1309.5421 - accuracy: 0.0000e+00\nEpoch 43/50\n8/8 [==============================] - 0s 51ms/step - loss: 1166.3547 - accuracy: 0.0000e+00\nEpoch 44/50\n8/8 [==============================] - 0s 46ms/step - loss: 1069.6406 - accuracy: 0.0156\nEpoch 45/50\n8/8 [==============================] - 0s 52ms/step - loss: 1094.9236 - accuracy: 0.0156\nEpoch 46/50\n8/8 [==============================] - 0s 56ms/step - loss: 1021.8777 - accuracy: 0.0000e+00\nEpoch 47/50\n8/8 [==============================] - 0s 49ms/step - loss: 977.1484 - accuracy: 0.0000e+00\nEpoch 48/50\n8/8 [==============================] - 0s 47ms/step - loss: 933.0396 - accuracy: 0.0000e+00\nEpoch 49/50\n8/8 [==============================] - 0s 43ms/step - loss: 873.0670 - accuracy: 0.0000e+00\nEpoch 50/50\n8/8 [==============================] - 1s 67ms/step - loss: 815.1061 - accuracy: 0.0156\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x17395d12910>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  my_training_batch_generator_cifar,\n",
    "  epochs=num_epochs,\n",
    "  validation_data = my_validation_batch_generator_cifar,\n",
    "  validation_steps=len(my_validation_batch_generator)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "height = 32\n",
    "width = 32\n",
    "num_features = height * width*  num_channels\n",
    "my_training_batch_generator_cifar = My_Custom_GeneratorURLs(X_train, y_train, batch_size, height, width)\n",
    "my_validation_batch_generator_cifar = My_Custom_GeneratorURLs(X_test, y_test, batch_size, height, width)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(num_features + num_classes))\n",
    "flatten_images = inputs[:, 0:num_features]\n",
    "# you can reshape output_1 and convert it in the original dataset\n",
    "flatten_images = tf.reshape(flatten_images, [-1, height, width, num_channels])\n",
    "\n",
    "flatten_images = tf.keras.applications.ResNet152V2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=( height, width, num_channels),\n",
    "    pooling=None,\n",
    "    classes=num_classes,\n",
    "    classifier_activation=None,\n",
    ")(flatten_images)\n",
    "\n",
    "\n",
    "# you can compare how faster is the ArcFace decreasing the loss\n",
    "#predictions = layers.Dense(num_classes, activation='softmax')(output_2)\n",
    "predictions = ArcFace(num_classes)(flatten_images, inputs[:, num_features: num_features + num_classes])  \n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n8/8 [==============================] - ETA: 0s - loss: 2108.5842 - accuracy: 0.0000e+00WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n8/8 [==============================] - 18s 2s/step - loss: 2108.5842 - accuracy: 0.0000e+00 - val_loss: 2596.6340 - val_accuracy: 0.0000e+00\nEpoch 2/5\n8/8 [==============================] - 9s 1s/step - loss: 2356.5134 - accuracy: 0.0000e+00\nEpoch 3/5\n8/8 [==============================] - 9s 1s/step - loss: 2371.3977 - accuracy: 0.0000e+00\nEpoch 4/5\n8/8 [==============================] - 8s 966ms/step - loss: 2395.7615 - accuracy: 0.0000e+00\nEpoch 5/5\n8/8 [==============================] - 6s 801ms/step - loss: 2464.9688 - accuracy: 0.0000e+00\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x173a4c84160>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  my_training_batch_generator_cifar,\n",
    "  epochs=num_epochs,\n",
    "  validation_data = my_validation_batch_generator_cifar,\n",
    "  validation_steps=len(my_validation_batch_generator)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}